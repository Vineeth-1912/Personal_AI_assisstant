
***

# ğŸ™ï¸ AI Voice Assistant with Real-Time Conversations

A **smart NLP-powered Voice Assistant** that listens, understands, thinks, and talks back in **real-time** â€” all powered by **Groqâ€™s ultra-fast LLM inference (LLaMA 3.3â€“70B)** and deployed via **Streamlit**.  

This assistant features **speech-to-text**, **humorous personality-driven responses**, and **text-to-speech** output â€” creating a natural, interactive conversational experience.  

***

## âœ¨ Features

- ğŸ§  **NLP Core:** Powered by **LLaMA 3.3â€“70B** via Groq API for lightning-fast responses.
- ğŸ™ï¸ **Real-Time Speech Recognition** using Pythonâ€™s `speech_recognition` package.
- ğŸ˜‚ **Custom Personality Mode** â€” responds in the style of **Brahmanandam**, the iconic South Indian comedy actor, delivering short, witty replies.
- ğŸ—£ **Voice Synthesis** with `pyttsx3` for instant audio responses.
- ğŸŒ **Streamlit Web UI** for an interactive browser-based voice chat.

***

## ğŸ›  Technologies Used

- **Python** â€” NLP + Audio Processing  
- **Groq API** â€” LLaMA 3.3â€“70B ultra-fast inference  
- **Streamlit** â€” Web-based UI framework  
- **SpeechRecognition** â€” Speech-to-text (STT)  
- **Pyttsx3** â€” Text-to-speech (TTS)  
- **Prompt Engineering** â€” For humorous, character-driven responses  

***

## ğŸ“š How It Works

1. **Voice Input (STT):** Listens to your voice and transcribes it using `speech_recognition`.
2. **LLM Interaction:** Sends the transcription to **Groqâ€™s LLaMA 3.3â€“70B** for intelligent, personalized replies.
3. **Custom Humor Personality:** Prompt engineering ensures replies sound like **Brahmanandam**.
4. **Voice Output (TTS):** Generates human-like voice using `pyttsx3` and plays it back in real time.
5. **Web UI:** Interact via a clean **Streamlit** interface.

***

## ğŸš€ Installation & Setup

### 1ï¸âƒ£ Clone this Repository
```bash
git clone https://github.com/yourusername/ai-voice-assistant.git
cd ai-voice-assistant
```

### 2ï¸âƒ£ Create & Activate Virtual Environment
```bash
python -m venv venv
source venv/bin/activate  # For Mac/Linux
venv\Scripts\activate     # For Windows
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set Your API Key Securely  
Create a `.env` file in the project root and add your Groq API key:
```env
GROQ_API_KEY=your_api_key_here
```
âš  **Never commit your API keys to GitHub**. Ensure `.env` is listed in `.gitignore`.

### 5ï¸âƒ£ Run the App
```bash
streamlit run app.py
```

***

## ğŸ–¼ Demo Screenshot  
<img width="1919" height="1012" alt="image" src="https://github.com/user-attachments/assets/ec68bae3-73cb-4025-b74b-df55e68ab496" />


***

## ğŸ” Example Conversation

**You:** "Hello, how are you?"  
**Assistant:** "Ahh! Nenu baagane unnaâ€¦ meeru coffee ivvaraa?" â˜• ğŸ˜„  

***

## ğŸ“Œ Future Improvements
- Support for multiple personality modes  
- Integration with real-time streaming STT for zero-latency input  
- More expressive voice synthesis  
- Mobile version using Kotlin or React Native  

***

## ğŸ“œ License
This project is licensed under the **MIT License** â€” free to use, modify, and share.

***

## ğŸ™Œ Acknowledgements
- [Groq](https://groq.com) for lightning-fast LLM inference  
- [Streamlit](https://streamlit.io/) for the UI magic  
- [SpeechRecognition](https://pypi.org/project/SpeechRecognition/) and [pyttsx3](https://pypi.org/project/pyttsx3/) for enabling the voice interface  

***
